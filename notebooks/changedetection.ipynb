{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKCqP2P5iwkr"
   },
   "source": [
    "# **Final change detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12024,
     "status": "ok",
     "timestamp": 1654584721745,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "eVkGK6ExYJ_E",
    "outputId": "38768880-2849-42d3-bc93-2e9b70b697df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NCWyUcji1-d"
   },
   "source": [
    "Empty the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1654586059238,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "9f4UC6hhN43u"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "shutil.rmtree('/content/drive/MyDrive/capstone/P_png')\n",
    "os.mkdir('/content/drive/MyDrive/capstone/P_png')\n",
    "#shutil.rmtree('/content/drive/MyDrive/capstone/P')\n",
    "#os.mkdir('/content/drive/MyDrive/capstone/P')\n",
    "shutil.rmtree('/content/drive/MyDrive/capstone/P cut')\n",
    "os.mkdir('/content/drive/MyDrive/capstone/P cut')\n",
    "shutil.rmtree('/content/drive/MyDrive/capstone/diff')\n",
    "os.mkdir('/content/drive/MyDrive/capstone/diff')\n",
    "shutil.rmtree('/content/drive/MyDrive/capstone/changemap')\n",
    "os.mkdir('/content/drive/MyDrive/capstone/changemap')\n",
    "shutil.rmtree('/content/drive/MyDrive/capstone/cleanchangemap')\n",
    "os.mkdir('/content/drive/MyDrive/capstone/cleanchangemap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LajkitF1iyuT"
   },
   "source": [
    "# Sentinel-2 data collection and cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q6CxoMUjD5N"
   },
   "source": [
    "If you want to use Sentinel 2 data you can follow these steps to modify the path, if you already have an image to detect you can skip this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIcLtWSNf389"
   },
   "source": [
    "## **1. Sentinel Data Download**\n",
    "\n",
    "1) ESA website: https://scihub.copernicus.eu/dhus/#/home\n",
    "\n",
    "2) Register an account or log in\n",
    "\n",
    "3) Select target region and data type (S2A_MSIL1C)\n",
    "\n",
    "4) Add data to the cart\n",
    "\n",
    "5) Download the .meta4 file and save it to the local PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUinl8o7gQNb"
   },
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "from data_downloader import downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXsHLhDKgUBM"
   },
   "outputs": [],
   "source": [
    "folder_out = r'D:\\sentinal2_data'  # A file that store output data\n",
    "url_file = r'D:\\sentinal2_data\\meta\\products.meta4'  # Downloaded the products.meta4 \n",
    "\n",
    "data = parse(url_file).documentElement\n",
    "urls = [i.childNodes[0].nodeValue for i in data.getElementsByTagName('url')]\n",
    "\n",
    "downloader.download_datas(urls,folder_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hj29k2Fga9N"
   },
   "source": [
    "## **2. Data Processing: atmospheric correction**\n",
    "\n",
    "1) Download Sen2Cor software : http://step.esa.int/main/third-party-plugins-2/sen2cor/\n",
    "\n",
    "2) Use command prompt to switch the path to the S2A_MSIL1C data\n",
    "\n",
    "3) Enter L2A_Process file name --resolution=10 --refresh command to process S2A_MSIL1C data and convert it to S2A_MSIL2A data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3xMr9lXgxHj"
   },
   "source": [
    "## **3. Data format conversion**\n",
    "Save sentinal data in Geotif format for subsequent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PXHTOR1gVdL"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr, ogr\n",
    "import glob\n",
    "os.environ['CPL_ZIP_ENCODING'] = 'UTF-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDJSiJblg6xn"
   },
   "outputs": [],
   "source": [
    "def S2tif(filename):\n",
    "\n",
    "    print(filename)\n",
    "    root_ds = gdal.Open(filename)    # Open the raster dataset\n",
    "    print(type(root_ds))\n",
    "    \"\"\"\n",
    "    The return result is a list. Each element in the list is a tuple. Each tuple contains a description of the path \n",
    "    to the dataset, metadata, and so on. The first element in the tuple describes the full path of the data subset.\n",
    "    \"\"\"\n",
    "    ds_list = root_ds.GetSubDatasets()  # Get the subdata set. \n",
    "    visual_ds = gdal.Open(ds_list[0][0])  # Open the path to the first data subset\n",
    "    visual_arr = visual_ds.ReadAsArray()  # Read the data in the dataset as ndarray\n",
    "    print(visual_arr.shape)\n",
    "    \n",
    "#     visual_ds = gdal.Open(ds_list[1][0])  #The ds_list has 4 subsets, the first part is the path and the rest part is the data information\n",
    "#     visual_arr = visual_ds.ReadAsArray()   \n",
    "#     visual_ds = gdal.Open(ds_list[2][0])  \n",
    "#     visual_arr = visual_ds.ReadAsArray()\n",
    "#     visual_ds = gdal.Open(ds_list[3][0])  \n",
    "#     visual_arr = visual_ds.ReadAsArray()\n",
    "\n",
    "\n",
    "    # Create Tif file\n",
    "    band_count = visual_ds.RasterCount # Band number\n",
    "    print(band_count)\n",
    "    xsize = visual_ds.RasterXSize\n",
    "    ysize = visual_ds.RasterYSize\n",
    "    out_tif_name = filename.split(\".SAFE\")[0] + \".tif\"\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    out_tif = driver.Create(out_tif_name, xsize, ysize, band_count, gdal.GDT_Float32)\n",
    "    out_tif.SetProjection(visual_ds.GetProjection())  # Set projection coordinates\n",
    "    out_tif.SetGeoTransform(visual_ds.GetGeoTransform())\n",
    "\n",
    "    for index, band in enumerate(visual_arr):\n",
    "        band = np.array([band])\n",
    "        for i in range(len(band[:])):\n",
    "            out_tif.GetRasterBand(index + 1).WriteArray(band[i]) # Writeout the data\n",
    "    out_tif.FlushCache()  # Synchronizes data to disks\n",
    "    out_tif = None  # Close the TIF file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2VyvVISg_o0"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from osgeo import gdal\n",
    "    SAFE_Path = (r'D:\\sentinal2_data\\L2A') # Tif file storage path\n",
    "    data_list = glob.glob(SAFE_Path + \"\\\\*.SAFE\")\n",
    "\n",
    "    #filename = ('E:\\\\RSDATA\\\\Sentinel2\\\\L2A\\\\S2A_MSIL2A_20210220T024731_N9999_R132_T51STA_20210306T024402.SAFE\\\\MTD_MSIL2A.xml')\n",
    "    for i in range(len(data_list)):\n",
    "        data_path = data_list[i]\n",
    "        filename = data_path + \"\\\\MTD_MSIL2A.xml\"\n",
    "        S2tif(filename)\n",
    "        print(data_path + \"-----Turn tif successfully \")\n",
    "    print(\"----Conversion end----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL0-nziWjPFh"
   },
   "source": [
    "# Cropping and formatting of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1654586108403,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "tZRSiDYNQLSr"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def Convert_To_Png_AndCut(dir):\n",
    "    files = os.listdir(dir)\n",
    "    ResultPath1 = \"/content/drive/MyDrive/capstone/P_png/\" # Define the path to save the format after conversion\n",
    "    ResultPath2 = \"/content/drive/MyDrive/capstone/P cut/\" # Define the save path after cropping\n",
    "    file_name = []\n",
    "    \n",
    "    for file in files:\n",
    "        a, b = os.path.splitext(file) # File name of the split image map\n",
    "        file_name.append(a)\n",
    "        this_dir = os.path.join(dir + file) # Build Save Path + Filename\n",
    "     \n",
    "        img = cv.imread(this_dir, 1) # Read tif images\n",
    "     \n",
    "        cv.imwrite(ResultPath1 + a + \"_\" + \".png\", img) # Save as png\n",
    "     \n",
    "        hight = img.shape[0] #Get width and height\n",
    "        width = img.shape[1]\n",
    "        #Defining the cut size\n",
    "        w = 650 # Width\n",
    "        h = 650 # Height\n",
    "        _id = 1 # Crop result save file name: 0 - N in ascending order\n",
    "        i = 0\n",
    "        row = 0\n",
    "        column = 0 \n",
    "        while (i + h <= hight): # Control the height and leave out the excess fixed size sum of the image\n",
    "            j = 0\n",
    "            row = row + 1\n",
    "            while (j + w <= width):  # Control the width and leave the excess fixed size sum of the image alone\n",
    "                column = column + 1\n",
    "                cropped = img[i:i + h, j:j + w] # Cropped coordinates are [y0:y1, x0:x1]\n",
    "                cv.imwrite(ResultPath2 + a + \"_\" + str(_id) + b, cropped)\n",
    "                _id += 1\n",
    "                j += w\n",
    "            i = i + h\n",
    "    column = column / row\n",
    "    return file_name[0], file_name[1], _id - 1, row, int(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 4003,
     "status": "ok",
     "timestamp": 1654586114543,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "87T5BetZQYQv"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    _path = \"/content/drive/MyDrive/capstone/P/\"  # Remote sensing tiff image location path\n",
    "    # Crop image map\n",
    "    after, before, number, row, column = Convert_To_Png_AndCut(_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmtpR8kcjEYn"
   },
   "source": [
    "# Change detection for unsupervised learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1654585120394,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "YOckP_sYQcda"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "import scipy\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU-GBiUWab4v"
   },
   "source": [
    "## **1. Difference image and the Eigen vector space**\n",
    "\n",
    "In this method,a non-overlapping blocks are taken of size 5 x 5 from the difference image and flatten them into row vectors. The image can be resized to make both the dimensions a multiple of 5 by scipy.misc.imresize(). Collection of these row vectors forms a vector set. In change_detection.py script, find_vector_set() does exactly this. If the size of our difference image is m x n, then the number of rows in the vector set would be {m x n}/{5 x 5} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1654585122351,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "_F9FfyFSQl_5"
   },
   "outputs": [],
   "source": [
    "def find_vector_set(diff_image, new_size):\n",
    "   \n",
    "    i = 0\n",
    "    j = 0\n",
    "    vector_set = np.zeros((int(new_size[0] * new_size[1] / 25), 25))\n",
    "\n",
    "    print('\\nvector_set shape',vector_set.shape)\n",
    "    \n",
    "    while i < vector_set.shape[0]:\n",
    "        while j < new_size[0]:\n",
    "            k = 0\n",
    "            while k < new_size[1]:\n",
    "                block   = diff_image[j:j+5, k:k+5]\n",
    "                #print(i,j,k,block.shape)\n",
    "                feature = block.ravel()\n",
    "                vector_set[i, :] = feature\n",
    "                k = k + 5\n",
    "            j = j + 5\n",
    "        i = i + 1\n",
    "        \n",
    "            \n",
    "    mean_vec   = np.mean(vector_set, axis = 0)    \n",
    "    vector_set = vector_set - mean_vec\n",
    "    \n",
    "    return vector_set, mean_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wA-RKeDahK5"
   },
   "source": [
    "## **2. Building the feature vector space**\n",
    "\n",
    "Building the FVS involves again taking 5 x 5 blocks from the difference image, flattening them, and lastly projecting them onto the EVS, only this time, the blocks will be overlapping. A vector space (VS) is first made by constructing one vector for each pixel of the difference image such a way that one 5 x 5 block is actually a pixel’s 5 x 5 neighborhood. It is to be noted here that by this logic, 4 boundary rows and 4 boundary columns pixels won’t get any feature vectors since they won’t have a 5 x 5 neighborhood. (We can manage with this exclusion of these pixels, since it is safe to assume here that any changes occurring would be concentrated in the middle regions of the images, rather than the edges). So, we will have (m x n)- 8 feature vectors in the FVS, all 25 dimensional. Projecting the FVS to the 25 dimensional EVS simply means to perform the following matrix multiplication\n",
    "\n",
    "(VS)((m x n - 8) x 25) .(EVS)(25 x 25) = (FVS)(m x n - 8) x 25\n",
    "\n",
    "Function find_FVS() determines the feature vector space for us. The function is similar to find_vector_set(), but extracts overlapping blocks from the difference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1654585124136,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "xalsFDNyQp66"
   },
   "outputs": [],
   "source": [
    "def find_FVS(EVS, diff_image, mean_vec, new):\n",
    "    \n",
    "    i = 2 \n",
    "    feature_vector_set = []\n",
    "    \n",
    "    while i < new[0] - 2:\n",
    "        j = 2\n",
    "        while j < new[1] - 2:\n",
    "            block = diff_image[i-2:i+3, j-2:j+3]\n",
    "            feature = block.flatten()\n",
    "            feature_vector_set.append(feature)\n",
    "            j = j+1\n",
    "        i = i+1\n",
    "        \n",
    "    FVS = np.dot(feature_vector_set, EVS)\n",
    "    FVS = FVS - mean_vec\n",
    "    print(\"\\nfeature vector space size\",FVS.shape)\n",
    "    return FVS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4F7RjYLaxjy"
   },
   "source": [
    "## **3. Clustering of the feature vector space, and change map**\n",
    "\n",
    "The feature vectors for the pixels carry information whether the pixels have characteristics of a changed pixel or an unchanged one. Having constructed the feature vector space, we now need to cluster it so that the pixels can be grouped into two disjoint classes. K-means algorithm is used to do that. Thus each pixel will get assigned to a cluster in such a way that the distance between the cluster’s mean vector and the pixel’s feature vector is the least. Each pixel gets a label from 1 to K, which denotes the cluster number that they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1654585126291,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "XryjXIYhQ_gM"
   },
   "outputs": [],
   "source": [
    "def clustering(FVS, components, new):\n",
    "    \n",
    "    kmeans = KMeans(components, verbose = 0)\n",
    "    kmeans.fit(FVS)\n",
    "    output = kmeans.predict(FVS)\n",
    "    count  = Counter(output)\n",
    "\n",
    "    least_index = min(count, key = count.get)            \n",
    "    print(new[0],new[1])\n",
    "    change_map  = np.reshape(output,(new[0] - 4, new[1] - 4))\n",
    "    \n",
    "    return least_index, change_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZOtqyaFa12u"
   },
   "source": [
    "During this experiments, it was empirically found that the best results were obtained with K = 3. Thus the argument components in clustering() will be 3. Remember, even though we have to do divide the pixels into 2 categories, we have chosen K = 3, instead of 2. Now how do we decide which of these clusters contains the pixels that belong to the changed class? It can be postulated that the cluster which contains the lowest number of pixels (denoted by variable least_index) is the cluster denoting the changed class, since the background remains more or less the same in satellite images and the changes occurred are comparatively less. Also, the mean of this cluster will be the highest. The reason behind the highest value of mean for that cluster is that the values of the difference image pixels in a region where some changes have occurred are higher than the values of pixels in the regions where there is no change.\n",
    "\n",
    "Thus, in conclusion, the cluster with the lowest number of pixels, and also the highest mean is the cluster belonging to the changed class.\n",
    "With this information, we will now build a change map – a binary image to show the output of change detection. We have chosen to keep the background black and will show the changes in white, i.e., intensity value of those pixels will be 255. You can do the reverse as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1654585128482,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "beJ_3jq4JkDD"
   },
   "outputs": [],
   "source": [
    "def find_PCAKmeans(imagepath1, imagepath2, after, i):\n",
    "    \n",
    "    print('Operating')\n",
    "    \n",
    "    image1 = cv2.imread(imagepath1)\n",
    "    image2 = cv2.imread(imagepath2)\n",
    "    image1=image1[:,:,0]\n",
    "    image2=image2[:,:,0]\n",
    "    print(image1.shape,image2.shape) \n",
    "    new_size = np.asarray(image1.shape) / 5\n",
    "    new_size = new_size.astype(int) * 5\n",
    "    image1 = resize(image1, (new_size))\n",
    "    image2 = resize(image2, (new_size))\n",
    "    diff_image = abs(image1 - image2)   \n",
    "    imageio.imwrite('/content/drive/MyDrive/capstone/diff/' + after + '_' + str(i) + '.png', diff_image)\n",
    "    print('\\nBoth images resized to ',new_size)\n",
    "        \n",
    "    vector_set, mean_vec = find_vector_set(diff_image, new_size)\n",
    "    pca     = PCA()\n",
    "    pca.fit(vector_set)\n",
    "    EVS = pca.components_   \n",
    "    FVS     = find_FVS(EVS, diff_image, mean_vec, new_size)\n",
    "    print('\\ncomputing k means')\n",
    "    \n",
    "    components = 3\n",
    "    least_index, change_map = clustering(FVS, components, new_size)\n",
    "    change_map[change_map == least_index] = 255 ## change map formula\n",
    "    change_map[change_map != 255] = 0   \n",
    "    change_map = change_map.astype(np.uint8)\n",
    "    kernel     = np.asarray(((0,0,1,0,0),\n",
    "                             (0,1,1,1,0),\n",
    "                             (1,1,1,1,1),\n",
    "                             (0,1,1,1,0),\n",
    "                             (0,0,1,0,0)), dtype=np.uint8)\n",
    "    cleanChangeMap = cv2.erode(change_map,kernel)\n",
    "    imageio.imwrite('/content/drive/MyDrive/capstone/changemap/' + after + '_' + str(i) + '.png', change_map)\n",
    "    imageio.imwrite('/content/drive/MyDrive/capstone/cleanchangemap/' + after + '_' + str(i) + '.png', cleanChangeMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542252,
     "status": "ok",
     "timestamp": 1654586667219,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "omgSpmg6QxuV",
    "outputId": "b5365c4f-8cc1-483f-a75f-1b9a4bfa2f50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  after removing the cwd from sys.path.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 650\n",
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating\n",
      "(650, 650) (650, 650)\n",
      "\n",
      "Both images resized to  [650 650]\n",
      "\n",
      "vector_set shape (16900, 25)\n",
      "\n",
      "feature vector space size (417316, 25)\n",
      "\n",
      "computing k means\n",
      "650 650\n"
     ]
    }
   ],
   "source": [
    "path = \"/content/drive/MyDrive/capstone/P cut/\"\n",
    "for i in range(1, number + 1):\n",
    "    a= path + before + '_' + str(i) + '.png'\n",
    "    b= path + after + '_' + str(i) + '.png'\n",
    "    find_PCAKmeans(a, b, after, i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlvdIlbYyfHq"
   },
   "source": [
    "# Image stitching and multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkkmtwjFYVsn"
   },
   "source": [
    "Stitching the images in the diff folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3178,
     "status": "ok",
     "timestamp": 1654586690623,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "Krdd-7B-V9Sd",
    "outputId": "2a54b6e0-680f-4cc0-f729-e2cbb659fa99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/diff/'\n",
    "IMAGES_FORMAT = ['.jpg', '.JPG','.jpeg', '.png']\n",
    "\n",
    "#row = 7\n",
    "#column = 10\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 650# Size of each small image\n",
    "\n",
    "IMAGE_ROW = row  # Image spacing, i.e. how many rows there are when combined into one image\n",
    "IMAGE_COLUMN = column  # Image spacing, i.e. how many columns there are when combined into one image\n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/stich result/'  # Address after image conversion\n",
    " \n",
    "# Get the names of all the images under the address of the image set\n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "x=image_names\n",
    "a='.'\n",
    "b='_'\n",
    "image_names.sort(key = lambda x:int(x.split(a)[0].split(b)[-2])) # Image sorting\n",
    "print(len(image_names))\n",
    "\n",
    "\n",
    " \n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN * IMAGE_SIZE, IMAGE_ROW * IMAGE_SIZE)) # Create a new image\n",
    "    # Iterate through the loop, pasting each image into the corresponding position in order\n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (IMAGE_SIZE, IMAGE_SIZE),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * IMAGE_SIZE, (y - 1) * IMAGE_SIZE))\n",
    "    to_image.save(IMAGE_SAVE_PATH + 'diff_merged.png') # Save new image\n",
    "image_compose() # Calling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C59FKLDGYi2z"
   },
   "source": [
    "Stitching the images in the changemap folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3680,
     "status": "ok",
     "timestamp": 1654586701054,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "INL5zo6PPLJn",
    "outputId": "97e5d41f-d495-402c-960f-f47a19426345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/changemap/'\n",
    "IMAGES_FORMAT = ['.jpg', '.JPG','.jpeg', '.png']\n",
    "\n",
    "#row = 7\n",
    "#column = 10\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 650# Size of each small image\n",
    "\n",
    "IMAGE_ROW = row  # Image spacing, i.e. how many rows there are when combined into one image\n",
    "IMAGE_COLUMN = column  # Image spacing, i.e. how many columns there are when combined into one image\n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/stich result/'  # Address after image conversion\n",
    " \n",
    "# Get the names of all the images under the address of the image set\n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "x=image_names\n",
    "a='.'\n",
    "b='_'\n",
    "image_names.sort(key = lambda x:int(x.split(a)[0].split(b)[-2])) # Image sorting\n",
    "print(len(image_names))\n",
    "\n",
    "\n",
    " \n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN * IMAGE_SIZE, IMAGE_ROW * IMAGE_SIZE)) # Create a new image\n",
    "    # Iterate through the loop, pasting each image into the corresponding position in order\n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (IMAGE_SIZE, IMAGE_SIZE),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * IMAGE_SIZE, (y - 1) * IMAGE_SIZE))\n",
    "    to_image.save(IMAGE_SAVE_PATH + 'changemap_merged.png') # Save new image\n",
    "image_compose() # Calling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pg5FLWOWYpQ2"
   },
   "source": [
    "Stitching the images in the cleanchangemap folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2753,
     "status": "ok",
     "timestamp": 1654586706032,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "GRO4xJl3dWHx",
    "outputId": "d6fe4945-de11-4537-d8e9-a167522a0a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/cleanchangemap/'\n",
    "IMAGES_FORMAT = ['.jpg', '.JPG','.jpeg', '.png']\n",
    "\n",
    "#row = 7\n",
    "#column = 10\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 650# Size of each small image\n",
    "\n",
    "IMAGE_ROW = row  # Image spacing, i.e. how many rows there are when combined into one image\n",
    "IMAGE_COLUMN = column  # Image spacing, i.e. how many columns there are when combined into one image\n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/stich result/'  # Address after image conversion\n",
    " \n",
    "# Get the names of all the images under the address of the image set\n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "x=image_names\n",
    "a='.'\n",
    "b='_'\n",
    "image_names.sort(key = lambda x:int(x.split(a)[0].split(b)[-2])) # Image sorting\n",
    "print(len(image_names))\n",
    "\n",
    "\n",
    " \n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN * IMAGE_SIZE, IMAGE_ROW * IMAGE_SIZE)) # Create a new image\n",
    "    # Iterate through the loop, pasting each image into the corresponding position in order\n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (IMAGE_SIZE, IMAGE_SIZE),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * IMAGE_SIZE, (y - 1) * IMAGE_SIZE))\n",
    "    to_image.save(IMAGE_SAVE_PATH + 'cleanchangemap_merged.png') # Save new image\n",
    "image_compose() # Calling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXzYbAK4Yxvd"
   },
   "source": [
    "Stitching images from the image label folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18955,
     "status": "ok",
     "timestamp": 1654053624904,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "Dsm6OUa49wGc",
    "outputId": "ac9f9b4e-d869-4562-d406-558f950bd4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/image label/'\n",
    "IMAGES_FORMAT = ['.jpg', '.JPG','.jpeg', '.png']\n",
    "\n",
    "#row = 21\n",
    "#column = 22\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 650# Size of each small image\n",
    "\n",
    "IMAGE_ROW = row  # Image spacing, i.e. how many rows there are when combined into one image\n",
    "IMAGE_COLUMN = column  # Image spacing, i.e. how many columns there are when combined into one image\n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/stich result/'  # Address after image conversion\n",
    " \n",
    "# Get the names of all the images under the address of the image set\n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "x=image_names\n",
    "a='.'\n",
    "b='_'\n",
    "image_names.sort(key = lambda x:int(x.split('.')[0]))\n",
    "print(len(image_names))\n",
    "\n",
    "\n",
    " \n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN * IMAGE_SIZE, IMAGE_ROW * IMAGE_SIZE)) # Create a new diagram\n",
    "    # Iterate through the loop, pasting each image into the corresponding position in order\n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (IMAGE_SIZE, IMAGE_SIZE),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * IMAGE_SIZE, (y - 1) * IMAGE_SIZE))\n",
    "    to_image.save(IMAGE_SAVE_PATH + 'labeled_merged.png') # Save new image\n",
    "image_compose() # Calling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RkADUmxY4aH"
   },
   "source": [
    "Multiplying diff images and labelled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZvTfRE3WgOw"
   },
   "outputs": [],
   "source": [
    "# Importing Image and ImageChops module from PIL package\n",
    "from PIL import Image, ImageChops\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\t\n",
    "# create label\n",
    "label = Image.open(r\"/content/drive/MyDrive/capstone/stich result/diff_merged.png\")\n",
    "\n",
    "# ValueError: images do not match, need to match image mode\n",
    "label = label.convert(\"RGB\")\n",
    "\n",
    "# creat mask\n",
    "mask = Image.open(r\"/content/drive/MyDrive/capstone/stich result/labeled_merged.png\")\n",
    "mask = mask.convert(\"RGB\")\t\n",
    "\n",
    "# applying multiply method\n",
    "im3 = ImageChops.multiply(label,mask)\n",
    "im3.save('/content/drive/MyDrive/capstone/stich result/multiply_diff.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF8rSMI8ZX_P"
   },
   "source": [
    "Multiplying changemap images and labelled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHx9XcRk9AyP"
   },
   "outputs": [],
   "source": [
    "# Importing Image and ImageChops module from PIL package\n",
    "from PIL import Image, ImageChops\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\t\n",
    "# create label\n",
    "label = Image.open(r\"/content/drive/MyDrive/capstone/stich result/changemap_merged.png\")\n",
    "\n",
    "# ValueError: images do not match, need to match image mode\n",
    "label = label.convert(\"RGB\")\n",
    "\n",
    "# creat mask\n",
    "mask = Image.open(r\"/content/drive/MyDrive/capstone/stich result/labeled_merged.png\")\n",
    "mask = mask.convert(\"RGB\")\t\n",
    "\n",
    "# applying multiply method\n",
    "im3 = ImageChops.multiply(label,mask)\n",
    "im3.save('/content/drive/MyDrive/capstone/stich result/multiply_changemap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RQ94gYCZJWO"
   },
   "source": [
    "Multiplying cleanchangmap images and labelled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtU1hksjV16N"
   },
   "outputs": [],
   "source": [
    "# Importing Image and ImageChops module from PIL package\n",
    "from PIL import Image, ImageChops\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\t\n",
    "# create label\n",
    "label = Image.open(r\"/content/drive/MyDrive/capstone/stich result/cleanchangemap_merged.png\")\n",
    "\n",
    "# ValueError: images do not match, need to match image mode\n",
    "label = label.convert(\"RGB\")\n",
    "\n",
    "# creat mask\n",
    "mask = Image.open(r\"/content/drive/MyDrive/capstone/stich result/labeled_merged.png\")\n",
    "mask = mask.convert(\"RGB\")\t\n",
    "\n",
    "# applying multiply method\n",
    "im3 = ImageChops.multiply(label,mask)\n",
    "im3.save('/content/drive/MyDrive/capstone/stich result/multiply_cleanchangemap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9850,
     "status": "ok",
     "timestamp": 1654455418458,
     "user": {
      "displayName": "崔新博",
      "userId": "00310808978341124447"
     },
     "user_tz": -480
    },
    "id": "FUASRPRWNzqK",
    "outputId": "0ee1a217-9e02-4d97-bb9b-b7a27e80a1f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/report/cleanchangemap/'\n",
    "IMAGES_FORMAT = ['.jpg', '.JPG','.jpeg', '.png']\n",
    "\n",
    "row = 5\n",
    "column = 7\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 650# Size of each small image\n",
    "\n",
    "IMAGE_ROW = row  # Image spacing, i.e. how many rows there are when combined into one image\n",
    "IMAGE_COLUMN = column  # Image spacing, i.e. how many columns there are when combined into one image\n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/stich result/'  # Address after image conversion\n",
    " \n",
    "# Get the names of all the images under the address of the image set\n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "x=image_names\n",
    "a='.'\n",
    "b='_'\n",
    "image_names.sort(key = lambda x:int(x.split(a)[0].split(b)[-2])) # Image sorting\n",
    "print(len(image_names))\n",
    "\n",
    "\n",
    " \n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN * IMAGE_SIZE, IMAGE_ROW * IMAGE_SIZE)) # Create a new image\n",
    "    # Iterate through the loop, pasting each image into the corresponding position in order\n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (IMAGE_SIZE, IMAGE_SIZE),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * IMAGE_SIZE, (y - 1) * IMAGE_SIZE))\n",
    "    to_image.save(IMAGE_SAVE_PATH + 'report_cleanchangemap.png') # Save new image\n",
    "image_compose() # Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Sf_da8BOm1q"
   },
   "outputs": [],
   "source": [
    "# Importing Image and ImageChops module from PIL package\n",
    "from PIL import Image, ImageChops\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\t\n",
    "# create label\n",
    "label = Image.open(r\"/content/drive/MyDrive/capstone/stich result/report_cleanchangemap.png\")\n",
    "\n",
    "# ValueError: images do not match, need to match image mode\n",
    "label = label.convert(\"RGB\")\n",
    "\n",
    "# creat mask\n",
    "mask = Image.open(r\"/content/drive/MyDrive/capstone/Unet++/report/label/compose_image_label.png\")\n",
    "mask = mask.convert(\"RGB\")\t\n",
    "\n",
    "# applying multiply method\n",
    "im3 = ImageChops.multiply(label,mask)\n",
    "im3.save('/content/drive/MyDrive/capstone/stich result/multiply_report_cleanchangemap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igS0klbzMGsw"
   },
   "source": [
    "# **Unet++ method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m3-KaxnM_sp"
   },
   "source": [
    "Run train.py to generate an evaluation image to update the model, if you want to use it directly you can ignore this step and use the trained model for change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3661026,
     "status": "ok",
     "timestamp": 1653746005317,
     "user": {
      "displayName": "Jiarun Zhu",
      "userId": "16642120945722264210"
     },
     "user_tz": -480
    },
    "id": "W-8KF1L9IIN2",
    "outputId": "d7e29ba1-3911-4f29-fcb2-c3750bf23d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using cuda\n",
      "INFO: Generating dataset ...\n",
      "INFO: Batch size: 1\n",
      "INFO: Dataset generated\n",
      "INFO: Network creation:\n",
      "\n",
      "INFO: Starting training : \n",
      "                Type : light Unet++\n",
      "                Epochs: 99\n",
      "                Batch size: 1\n",
      "                Data Augmentation: 2\n",
      "                Learning rate: 0.001\n",
      "                Device: cuda\n",
      "                Reloading model : False\n",
      "                Saving model : False\n",
      "/content/drive/MyDrive/Lamboise-Master/train.py:84: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  for epochs in range(0, num_epochs):\n",
      "INFO: Epoch 0.0\n",
      "Epoch 0.0: 44img [00:16,  2.67img/s, loss=0.665]\n",
      "Validation: 10img [00:01,  5.09img/s, loss=tensor(7.4145, device='cuda:0')]\n",
      "INFO: Train loss 0.6616742041977969\n",
      "INFO: Test loss  0.831049382686615\n",
      "INFO: Epoch 1.0\n",
      "Epoch 1.0: 44img [00:16,  2.63img/s, loss=0.661]\n",
      "Validation: 10img [00:02,  4.75img/s, loss=tensor(7.1315, device='cuda:0')]\n",
      "INFO: Train loss 0.6455296603116122\n",
      "INFO: Test loss  0.7918770909309387\n",
      "INFO: Epoch 2.0\n",
      "Epoch 2.0: 44img [00:16,  2.60img/s, loss=0.653]\n",
      "Validation: 10img [00:02,  4.96img/s, loss=tensor(6.2614, device='cuda:0')]\n",
      "INFO: Train loss 0.6265513747930529\n",
      "INFO: Test loss  0.6914581060409546\n",
      "INFO: Epoch 3.0\n",
      "Epoch 3.0: 44img [00:17,  2.57img/s, loss=0.641]\n",
      "Validation: 10img [00:02,  4.76img/s, loss=tensor(6.6011, device='cuda:0')]\n",
      "INFO: Train loss 0.6167127239433202\n",
      "INFO: Test loss  0.7311205267906189\n",
      "INFO: Epoch 4.0\n",
      "Epoch 4.0: 44img [00:16,  2.60img/s, loss=0.657]\n",
      "Validation: 10img [00:02,  4.96img/s, loss=tensor(5.5670, device='cuda:0')]\n",
      "INFO: Train loss 0.619252222505483\n",
      "INFO: Test loss  0.6178714632987976\n",
      "INFO: Epoch 5.0\n",
      "Epoch 5.0: 44img [00:16,  2.59img/s, loss=0.631]\n",
      "Validation: 10img [00:02,  4.96img/s, loss=tensor(5.5792, device='cuda:0')]\n",
      "INFO: Train loss 0.6177244823087344\n",
      "INFO: Test loss  0.6210387349128723\n",
      "INFO: Epoch 6.0\n",
      "Epoch 6.0: 44img [00:17,  2.59img/s, loss=0.622]\n",
      "Validation: 10img [00:01,  5.15img/s, loss=tensor(5.7917, device='cuda:0')]\n",
      "INFO: Train loss 0.6041387861425226\n",
      "INFO: Test loss  0.6386697888374329\n",
      "INFO: Epoch 7.0\n",
      "Epoch 7.0: 44img [00:16,  2.59img/s, loss=0.633]\n",
      "Validation: 10img [00:02,  4.85img/s, loss=tensor(5.5410, device='cuda:0')]\n",
      "INFO: Train loss 0.5891914530233904\n",
      "INFO: Test loss  0.6100804209709167\n",
      "INFO: Epoch 8.0\n",
      "Epoch 8.0: 44img [00:16,  2.59img/s, loss=0.609]\n",
      "Validation: 10img [00:01,  5.19img/s, loss=tensor(5.6866, device='cuda:0')]\n",
      "INFO: Train loss 0.5812635611404072\n",
      "INFO: Test loss  0.6252520680427551\n",
      "INFO: Epoch 9.0\n",
      "Epoch 9.0: 44img [00:16,  2.60img/s, loss=0.599]\n",
      "Validation: 10img [00:02,  4.89img/s, loss=tensor(6.2216, device='cuda:0')]\n",
      "INFO: Train loss 0.5799380906603554\n",
      "INFO: Test loss  0.6881828904151917\n",
      "INFO: Epoch 10.0\n",
      "Epoch 10.0: 44img [00:17,  2.59img/s, loss=0.595]\n",
      "Validation: 10img [00:02,  4.97img/s, loss=tensor(5.1749, device='cuda:0')]\n",
      "INFO: Train loss 0.5729482363570819\n",
      "INFO: Test loss  0.5756951570510864\n",
      "INFO: Epoch 11.0\n",
      "Epoch 11.0: 44img [00:16,  2.59img/s, loss=0.603]\n",
      "Validation: 10img [00:02,  4.99img/s, loss=tensor(6.0022, device='cuda:0')]\n",
      "INFO: Train loss 0.5763153332200917\n",
      "INFO: Test loss  0.6607304215431213\n",
      "INFO: Epoch 12.0\n",
      "Epoch 12.0: 44img [00:16,  2.60img/s, loss=0.574]\n",
      "Validation: 10img [00:01,  5.04img/s, loss=tensor(5.0709, device='cuda:0')]\n",
      "INFO: Train loss 0.5630093142390251\n",
      "INFO: Test loss  0.5644736289978027\n",
      "INFO: Epoch 13.0\n",
      "Epoch 13.0: 44img [00:17,  2.59img/s, loss=0.58]\n",
      "Validation: 10img [00:01,  5.02img/s, loss=tensor(6.0302, device='cuda:0')]\n",
      "INFO: Train loss 0.5582812103358182\n",
      "INFO: Test loss  0.6731846928596497\n",
      "INFO: Epoch 14.0\n",
      "Epoch 14.0: 44img [00:16,  2.59img/s, loss=0.569]\n",
      "Validation: 10img [00:01,  5.04img/s, loss=tensor(5.9410, device='cuda:0')]\n",
      "INFO: Train loss 0.5543704872781579\n",
      "INFO: Test loss  0.6548217535018921\n",
      "INFO: Epoch 15.0\n",
      "Epoch 15.0: 44img [00:16,  2.59img/s, loss=0.564]\n",
      "Validation: 10img [00:01,  5.09img/s, loss=tensor(5.1333, device='cuda:0')]\n",
      "INFO: Train loss 0.5477559966119853\n",
      "INFO: Test loss  0.5661386847496033\n",
      "INFO: Epoch 16.0\n",
      "Epoch 16.0: 44img [00:17,  2.59img/s, loss=0.561]\n",
      "Validation: 10img [00:01,  5.10img/s, loss=tensor(5.3596, device='cuda:0')]\n",
      "INFO: Train loss 0.5469121594320643\n",
      "INFO: Test loss  0.5922906398773193\n",
      "INFO: Epoch 17.0\n",
      "Epoch 17.0: 44img [00:16,  2.59img/s, loss=0.566]\n",
      "Validation: 10img [00:02,  4.91img/s, loss=tensor(5.5332, device='cuda:0')]\n",
      "INFO: Train loss 0.5395086644725366\n",
      "INFO: Test loss  0.6089307069778442\n",
      "INFO: Epoch 18.0\n",
      "Epoch 18.0: 44img [00:16,  2.59img/s, loss=0.551]\n",
      "Validation: 10img [00:01,  5.21img/s, loss=tensor(4.6441, device='cuda:0')]\n",
      "INFO: Train loss 0.5374551652507349\n",
      "INFO: Test loss  0.517221987247467\n",
      "INFO: Epoch 19.0\n",
      "Epoch 19.0: 44img [00:16,  2.59img/s, loss=0.546]\n",
      "Validation: 10img [00:01,  5.09img/s, loss=tensor(5.4960, device='cuda:0')]\n",
      "INFO: Train loss 0.528463836420666\n",
      "INFO: Test loss  0.6032356023788452\n",
      "INFO: Epoch 20.0\n",
      "Epoch 20.0: 44img [00:17,  2.59img/s, loss=0.543]\n",
      "Validation: 10img [00:01,  5.05img/s, loss=tensor(6.3985, device='cuda:0')]\n",
      "INFO: Train loss 0.5313856500116261\n",
      "INFO: Test loss  0.7052225470542908\n",
      "INFO: Epoch 21.0\n",
      "Epoch 21.0: 44img [00:17,  2.59img/s, loss=0.563]\n",
      "Validation: 10img [00:01,  5.00img/s, loss=tensor(5.1837, device='cuda:0')]\n",
      "INFO: Train loss 0.5273884961550885\n",
      "INFO: Test loss  0.574792206287384\n",
      "INFO: Epoch 22.0\n",
      "Epoch 22.0: 44img [00:16,  2.59img/s, loss=0.533]\n",
      "Validation: 10img [00:02,  4.98img/s, loss=tensor(4.5154, device='cuda:0')]\n",
      "INFO: Train loss 0.5204405019229109\n",
      "INFO: Test loss  0.5046496987342834\n",
      "INFO: Epoch 23.0\n",
      "Epoch 23.0: 44img [00:16,  2.59img/s, loss=0.538]\n",
      "Validation: 10img [00:01,  5.27img/s, loss=tensor(4.6785, device='cuda:0')]\n",
      "INFO: Train loss 0.5253357074477455\n",
      "INFO: Test loss  0.521055281162262\n",
      "INFO: Epoch 24.0\n",
      "Epoch 24.0: 44img [00:16,  2.59img/s, loss=0.53]\n",
      "Validation: 10img [00:02,  4.92img/s, loss=tensor(6.1140, device='cuda:0')]\n",
      "INFO: Train loss 0.5171538774262775\n",
      "INFO: Test loss  0.6767817735671997\n",
      "INFO: Epoch 25.0\n",
      "Epoch 25.0: 44img [00:16,  2.59img/s, loss=0.524]\n",
      "Validation: 10img [00:01,  5.11img/s, loss=tensor(6.0386, device='cuda:0')]\n",
      "INFO: Train loss 0.5127978067506443\n",
      "INFO: Test loss  0.6730238795280457\n",
      "INFO: Epoch 26.0\n",
      "Epoch 26.0: 44img [00:16,  2.60img/s, loss=0.554]\n",
      "Validation: 10img [00:02,  4.86img/s, loss=tensor(4.8679, device='cuda:0')]\n",
      "INFO: Train loss 0.5145042667334729\n",
      "INFO: Test loss  0.5387523174285889\n",
      "INFO: Epoch 27.0\n",
      "Epoch 27.0: 44img [00:16,  2.60img/s, loss=0.515]\n",
      "Validation: 10img [00:01,  5.14img/s, loss=tensor(4.5892, device='cuda:0')]\n",
      "INFO: Train loss 0.5105471604249694\n",
      "INFO: Test loss  0.5051693320274353\n",
      "INFO: Epoch 28.0\n",
      "Epoch 28.0: 44img [00:16,  2.60img/s, loss=0.516]\n",
      "Validation: 10img [00:02,  4.95img/s, loss=tensor(4.4767, device='cuda:0')]\n",
      "INFO: Train loss 0.5056764476678588\n",
      "INFO: Test loss  0.49661168456077576\n",
      "INFO: Epoch 29.0\n",
      "Epoch 29.0: 44img [00:16,  2.59img/s, loss=0.512]\n",
      "Validation: 10img [00:01,  5.07img/s, loss=tensor(4.6736, device='cuda:0')]\n",
      "INFO: Train loss 0.5008845092220741\n",
      "INFO: Test loss  0.5165700316429138\n",
      "INFO: Epoch 30.0\n",
      "Epoch 30.0: 44img [00:16,  2.60img/s, loss=0.513]\n",
      "Validation: 10img [00:01,  5.16img/s, loss=tensor(4.5145, device='cuda:0')]\n",
      "INFO: Train loss 0.5041774755174464\n",
      "INFO: Test loss  0.5017860531806946\n",
      "INFO: Epoch 31.0\n",
      "Epoch 31.0: 44img [00:16,  2.60img/s, loss=0.518]\n",
      "Validation: 10img [00:01,  5.12img/s, loss=tensor(4.2037, device='cuda:0')]\n",
      "INFO: Train loss 0.4952975159341638\n",
      "INFO: Test loss  0.47255179286003113\n",
      "INFO: Epoch 32.0\n",
      "Epoch 32.0: 44img [00:16,  2.59img/s, loss=0.508]\n",
      "Validation: 10img [00:02,  4.91img/s, loss=tensor(5.0066, device='cuda:0')]\n",
      "INFO: Train loss 0.49328410015864826\n",
      "INFO: Test loss  0.5502551794052124\n",
      "INFO: Epoch 33.0\n",
      "Epoch 33.0: 44img [00:17,  2.58img/s, loss=0.498]\n",
      "Validation: 10img [00:01,  5.14img/s, loss=tensor(5.5337, device='cuda:0')]\n",
      "INFO: Train loss 0.4867885275320573\n",
      "INFO: Test loss  0.6020799875259399\n",
      "INFO: Epoch 34.0\n",
      "Epoch 34.0: 44img [00:16,  2.59img/s, loss=0.491]\n",
      "Validation: 10img [00:02,  4.96img/s, loss=tensor(4.2431, device='cuda:0')]\n",
      "INFO: Train loss 0.4803263863379305\n",
      "INFO: Test loss  0.47518834471702576\n",
      "INFO: Epoch 35.0\n",
      "Epoch 35.0: 44img [00:17,  2.59img/s, loss=0.495]\n",
      "Validation: 10img [00:01,  5.07img/s, loss=tensor(4.2431, device='cuda:0')]\n",
      "INFO: Train loss 0.4809311072934758\n",
      "INFO: Test loss  0.47563740611076355\n",
      "INFO: Epoch 36.0\n",
      "Epoch 36.0: 44img [00:16,  2.59img/s, loss=0.477]\n",
      "Validation: 10img [00:01,  5.04img/s, loss=tensor(4.5404, device='cuda:0')]\n",
      "INFO: Train loss 0.47774175622246473\n",
      "INFO: Test loss  0.5087341070175171\n",
      "INFO: Epoch 37.0\n",
      "Epoch 37.0: 44img [00:16,  2.59img/s, loss=0.49]\n",
      "Validation: 10img [00:01,  5.10img/s, loss=tensor(4.2425, device='cuda:0')]\n",
      "INFO: Train loss 0.4833341850475832\n",
      "INFO: Test loss  0.4731307923793793\n",
      "INFO: Epoch 38.0\n",
      "Epoch 38.0: 44img [00:16,  2.59img/s, loss=0.512]\n",
      "Validation: 10img [00:02,  4.79img/s, loss=tensor(4.9210, device='cuda:0')]\n",
      "INFO: Train loss 0.48638557507233177\n",
      "INFO: Test loss  0.5471252799034119\n",
      "INFO: Epoch 39.0\n",
      "Epoch 39.0: 44img [00:16,  2.60img/s, loss=0.492]\n",
      "Validation: 10img [00:01,  5.00img/s, loss=tensor(6.9252, device='cuda:0')]\n",
      "INFO: Train loss 0.4830936403437095\n",
      "INFO: Test loss  0.7725209593772888\n",
      "INFO: Epoch 40.0\n",
      "Epoch 40.0: 44img [00:16,  2.59img/s, loss=0.479]\n",
      "Validation: 10img [00:01,  5.01img/s, loss=tensor(4.8204, device='cuda:0')]\n",
      "INFO: Train loss 0.47502451931888406\n",
      "INFO: Test loss  0.5284375548362732\n",
      "INFO: Epoch 41.0\n",
      "Epoch 41.0: 44img [00:16,  2.59img/s, loss=0.468]\n",
      "Validation: 10img [00:02,  4.84img/s, loss=tensor(5.3507, device='cuda:0')]\n",
      "INFO: Train loss 0.4667754742232235\n",
      "INFO: Test loss  0.5967496633529663\n",
      "INFO: Epoch 42.0\n",
      "Epoch 42.0: 44img [00:16,  2.59img/s, loss=0.463]\n",
      "Validation: 10img [00:02,  4.99img/s, loss=tensor(4.3318, device='cuda:0')]\n",
      "INFO: Train loss 0.45977124165404926\n",
      "INFO: Test loss  0.48209723830223083\n",
      "INFO: Epoch 43.0\n",
      "Epoch 43.0: 44img [00:16,  2.59img/s, loss=0.461]\n",
      "Validation: 10img [00:02,  4.95img/s, loss=tensor(4.4715, device='cuda:0')]\n",
      "INFO: Train loss 0.467830163511363\n",
      "INFO: Test loss  0.4993177354335785\n",
      "INFO: Epoch 44.0\n",
      "Epoch 44.0: 44img [00:17,  2.58img/s, loss=0.463]\n",
      "Validation: 10img [00:02,  4.96img/s, loss=tensor(4.3870, device='cuda:0')]\n",
      "INFO: Train loss 0.4640133590860801\n",
      "INFO: Test loss  0.48231664299964905\n",
      "INFO: Epoch 45.0\n",
      "Epoch 45.0: 44img [00:16,  2.59img/s, loss=0.459]\n",
      "Validation: 10img [00:01,  5.10img/s, loss=tensor(4.5656, device='cuda:0')]\n",
      "INFO: Train loss 0.4534524638544428\n",
      "INFO: Test loss  0.5057847499847412\n",
      "INFO: Epoch 46.0\n",
      "Epoch 46.0: 44img [00:17,  2.58img/s, loss=0.447]\n",
      "Validation: 10img [00:02,  4.86img/s, loss=tensor(4.6796, device='cuda:0')]\n",
      "INFO: Train loss 0.44347587972879404\n",
      "INFO: Test loss  0.5200765132904053\n",
      "INFO: Epoch 47.0\n",
      "Epoch 47.0: 44img [00:16,  2.60img/s, loss=0.446]\n",
      "Validation: 10img [00:01,  5.18img/s, loss=tensor(4.5342, device='cuda:0')]\n",
      "INFO: Train loss 0.45107988742264843\n",
      "INFO: Test loss  0.5029298663139343\n",
      "INFO: Epoch 48.0\n",
      "Epoch 48.0: 44img [00:16,  2.59img/s, loss=0.444]\n",
      "Validation: 10img [00:01,  5.14img/s, loss=tensor(6.0868, device='cuda:0')]\n",
      "INFO: Train loss 0.4582385542717847\n",
      "INFO: Test loss  0.6742247343063354\n",
      "INFO: Epoch 49.0\n",
      "Epoch 49.0: 44img [00:16,  2.60img/s, loss=0.438]\n",
      "Validation: 10img [00:01,  5.02img/s, loss=tensor(5.0868, device='cuda:0')]\n",
      "INFO: Train loss 0.4412231059236959\n",
      "INFO: Test loss  0.5596082210540771\n",
      "INFO: Epoch 50.0\n",
      "Epoch 50.0: 44img [00:16,  2.59img/s, loss=0.427]\n",
      "Validation: 10img [00:01,  5.13img/s, loss=tensor(5.3401, device='cuda:0')]\n",
      "INFO: Train loss 0.4364855242046443\n",
      "INFO: Test loss  0.5882784724235535\n",
      "INFO: Epoch 51.0\n",
      "Epoch 51.0: 44img [00:16,  2.59img/s, loss=0.421]\n",
      "Validation: 10img [00:01,  5.13img/s, loss=tensor(4.7813, device='cuda:0')]\n",
      "INFO: Train loss 0.4387558359991421\n",
      "INFO: Test loss  0.5257633328437805\n",
      "INFO: Epoch 52.0\n",
      "Epoch 52.0: 44img [00:16,  2.60img/s, loss=0.423]\n",
      "Validation: 10img [00:01,  5.18img/s, loss=tensor(4.5866, device='cuda:0')]\n",
      "INFO: Train loss 0.43263885920697986\n",
      "INFO: Test loss  0.5052971243858337\n",
      "INFO: Epoch 53.0\n",
      "Epoch 53.0: 44img [00:16,  2.59img/s, loss=0.439]\n",
      "Validation: 10img [00:01,  5.15img/s, loss=tensor(5.4471, device='cuda:0')]\n",
      "INFO: Train loss 0.43867718902501185\n",
      "INFO: Test loss  0.6088030934333801\n",
      "INFO: Epoch 54.0\n",
      "Epoch 54.0: 44img [00:16,  2.60img/s, loss=0.419]\n",
      "Validation: 10img [00:01,  5.17img/s, loss=tensor(4.1262, device='cuda:0')]\n",
      "INFO: Train loss 0.4334818612445485\n",
      "INFO: Test loss  0.4625765383243561\n",
      "INFO: Epoch 55.0\n",
      "Epoch 55.0: 44img [00:17,  2.59img/s, loss=0.42]\n",
      "Validation: 10img [00:01,  5.14img/s, loss=tensor(4.3631, device='cuda:0')]\n",
      "INFO: Train loss 0.429940403862433\n",
      "INFO: Test loss  0.4823988080024719\n",
      "INFO: Epoch 56.0\n",
      "Epoch 56.0: 44img [00:16,  2.60img/s, loss=0.416]\n",
      "Validation: 10img [00:01,  5.15img/s, loss=tensor(4.1016, device='cuda:0')]\n",
      "INFO: Train loss 0.4220967008308931\n",
      "INFO: Test loss  0.460756778717041\n",
      "INFO: Epoch 57.0\n",
      "Epoch 57.0: 44img [00:16,  2.59img/s, loss=0.405]\n",
      "Validation: 10img [00:01,  5.15img/s, loss=tensor(4.2204, device='cuda:0')]\n",
      "INFO: Train loss 0.4205528240312229\n",
      "INFO: Test loss  0.46596431732177734\n",
      "INFO: Epoch 58.0\n",
      "Epoch 58.0: 44img [00:16,  2.60img/s, loss=0.407]\n",
      "Validation: 10img [00:01,  5.14img/s, loss=tensor(4.0379, device='cuda:0')]\n",
      "INFO: Train loss 0.4194803204048765\n",
      "INFO: Test loss  0.4497557282447815\n",
      "INFO: Epoch 59.0\n",
      "Epoch 59.0: 44img [00:16,  2.59img/s, loss=0.409]\n",
      "Validation: 10img [00:02,  4.66img/s, loss=tensor(4.1214, device='cuda:0')]\n",
      "INFO: Train loss 0.41819052330472256\n",
      "INFO: Test loss  0.45988598465919495\n",
      "INFO: Epoch 60.0\n",
      "Epoch 60.0: 44img [00:17,  2.58img/s, loss=0.409]\n",
      "Validation: 10img [00:02,  4.97img/s, loss=tensor(4.0704, device='cuda:0')]\n",
      "INFO: Train loss 0.40914192186160525\n",
      "INFO: Test loss  0.4531918466091156\n",
      "INFO: Epoch 61.0\n",
      "Epoch 61.0: 44img [00:16,  2.59img/s, loss=0.404]\n",
      "Validation: 10img [00:01,  5.08img/s, loss=tensor(4.0237, device='cuda:0')]\n",
      "INFO: Train loss 0.4116395244544202\n",
      "INFO: Test loss  0.4491511285305023\n",
      "INFO: Epoch 62.0\n",
      "Epoch 62.0: 44img [00:16,  2.60img/s, loss=0.401]\n",
      "Validation: 10img [00:01,  5.18img/s, loss=tensor(4.0017, device='cuda:0')]\n",
      "INFO: Train loss 0.4093888103961944\n",
      "INFO: Test loss  0.44787144660949707\n",
      "INFO: Epoch 63.0\n",
      "Epoch 63.0: 44img [00:16,  2.59img/s, loss=0.396]\n",
      "Validation: 10img [00:01,  5.03img/s, loss=tensor(4.1061, device='cuda:0')]\n",
      "INFO: Train loss 0.40442238003015524\n",
      "INFO: Test loss  0.45589810609817505\n",
      "INFO: Epoch 64.0\n",
      "Epoch 64.0: 44img [00:17,  2.59img/s, loss=0.393]\n",
      "Validation: 10img [00:02,  4.99img/s, loss=tensor(4.3026, device='cuda:0')]\n",
      "INFO: Train loss 0.40006867863915185\n",
      "INFO: Test loss  0.4722196161746979\n",
      "INFO: Epoch 65.0\n",
      "Epoch 65.0: 44img [00:16,  2.60img/s, loss=0.44]\n",
      "Validation: 10img [00:01,  5.09img/s, loss=tensor(3.9724, device='cuda:0')]\n",
      "INFO: Train loss 0.3993241631171921\n",
      "INFO: Test loss  0.44396719336509705\n",
      "INFO: Epoch 66.0\n",
      "Epoch 66.0: 44img [00:16,  2.59img/s, loss=0.389]\n",
      "Validation: 10img [00:02,  4.79img/s, loss=tensor(4.2801, device='cuda:0')]\n",
      "INFO: Train loss 0.3970953889868477\n",
      "INFO: Test loss  0.47355028986930847\n",
      "INFO: Epoch 67.0\n",
      "Epoch 67.0: 44img [00:17,  2.59img/s, loss=0.399]\n",
      "Validation: 10img [00:01,  5.12img/s, loss=tensor(4.5113, device='cuda:0')]\n",
      "INFO: Train loss 0.40617347102273593\n",
      "INFO: Test loss  0.5048186779022217\n",
      "INFO: Epoch 68.0\n",
      "Epoch 68.0: 44img [00:16,  2.59img/s, loss=0.384]\n",
      "Validation: 10img [00:01,  5.01img/s, loss=tensor(4.3227, device='cuda:0')]\n",
      "INFO: Train loss 0.3983789215033704\n",
      "INFO: Test loss  0.47377249598503113\n",
      "INFO: Epoch 69.0\n",
      "Epoch 69.0: 44img [00:16,  2.60img/s, loss=0.434]\n",
      "Validation: 10img [00:01,  5.06img/s, loss=tensor(4.3119, device='cuda:0')]\n",
      "INFO: Train loss 0.4009001857855104\n",
      "INFO: Test loss  0.47906526923179626\n",
      "INFO: Epoch 70.0\n",
      "Epoch 70.0: 44img [00:16,  2.59img/s, loss=0.383]\n",
      "Validation: 10img [00:01,  5.06img/s, loss=tensor(3.9061, device='cuda:0')]\n",
      "INFO: Train loss 0.3921458213166757\n",
      "INFO: Test loss  0.43712353706359863\n",
      "INFO: Epoch 71.0\n",
      "Epoch 71.0: 44img [00:16,  2.59img/s, loss=0.385]\n",
      "Validation: 10img [00:01,  5.08img/s, loss=tensor(4.0154, device='cuda:0')]\n",
      "INFO: Train loss 0.39479240097782836\n",
      "INFO: Test loss  0.4514959752559662\n",
      "INFO: Epoch 72.0\n",
      "Epoch 72.0: 44img [00:16,  2.59img/s, loss=0.381]\n",
      "Validation: 10img [00:02,  4.96img/s, loss=tensor(3.9226, device='cuda:0')]\n",
      "INFO: Train loss 0.39139081469990994\n",
      "INFO: Test loss  0.4371703267097473\n",
      "INFO: Epoch 73.0\n",
      "Epoch 73.0: 44img [00:16,  2.59img/s, loss=0.391]\n",
      "Validation: 10img [00:01,  5.10img/s, loss=tensor(3.9074, device='cuda:0')]\n",
      "INFO: Train loss 0.4012844562530517\n",
      "INFO: Test loss  0.4376572072505951\n",
      "INFO: Epoch 74.0\n",
      "Epoch 74.0: 44img [00:16,  2.60img/s, loss=0.378]\n",
      "Validation: 10img [00:01,  5.00img/s, loss=tensor(4.0150, device='cuda:0')]\n",
      "INFO: Train loss 0.3915372375737537\n",
      "INFO: Test loss  0.4470054805278778\n",
      "INFO: Epoch 75.0\n",
      "Epoch 75.0: 44img [00:16,  2.60img/s, loss=0.385]\n",
      "Validation: 10img [00:01,  5.07img/s, loss=tensor(3.9243, device='cuda:0')]\n",
      "INFO: Train loss 0.392708340829069\n",
      "INFO: Test loss  0.43664613366127014\n",
      "INFO: Epoch 76.0\n",
      "Epoch 76.0: 44img [00:16,  2.59img/s, loss=0.373]\n",
      "Validation: 10img [00:02,  4.92img/s, loss=tensor(4.3427, device='cuda:0')]\n",
      "INFO: Train loss 0.3872362436218695\n",
      "INFO: Test loss  0.47470661997795105\n",
      "INFO: Epoch 77.0\n",
      "Epoch 77.0: 44img [00:16,  2.59img/s, loss=0.38]\n",
      "Validation: 10img [00:01,  5.06img/s, loss=tensor(4.2655, device='cuda:0')]\n",
      "INFO: Train loss 0.38630241155624395\n",
      "INFO: Test loss  0.47160348296165466\n",
      "INFO: Epoch 78.0\n",
      "Epoch 78.0: 44img [00:16,  2.59img/s, loss=0.369]\n",
      "Validation: 10img [00:01,  5.07img/s, loss=tensor(3.9700, device='cuda:0')]\n",
      "INFO: Train loss 0.38574814660982654\n",
      "INFO: Test loss  0.4419335424900055\n",
      "INFO: Epoch 79.0\n",
      "Epoch 79.0: 44img [00:16,  2.60img/s, loss=0.381]\n",
      "Validation: 10img [00:01,  5.05img/s, loss=tensor(4.2011, device='cuda:0')]\n",
      "INFO: Train loss 0.3838282620364967\n",
      "INFO: Test loss  0.46074652671813965\n",
      "INFO: Epoch 80.0\n",
      "Epoch 80.0: 44img [00:16,  2.60img/s, loss=0.376]\n",
      "Validation: 10img [00:01,  5.09img/s, loss=tensor(4.3881, device='cuda:0')]\n",
      "INFO: Train loss 0.3847107060930946\n",
      "INFO: Test loss  0.48148345947265625\n",
      "INFO: Epoch 81.0\n",
      "Epoch 81.0: 44img [00:16,  2.59img/s, loss=0.369]\n",
      "Validation: 10img [00:01,  5.08img/s, loss=tensor(4.2465, device='cuda:0')]\n",
      "INFO: Train loss 0.3826688819310882\n",
      "INFO: Test loss  0.46756306290626526\n",
      "INFO: Epoch 82.0\n",
      "Epoch 82.0: 44img [00:16,  2.59img/s, loss=0.368]\n",
      "Validation: 10img [00:02,  4.72img/s, loss=tensor(3.9836, device='cuda:0')]\n",
      "INFO: Train loss 0.380908615887165\n",
      "INFO: Test loss  0.4421451985836029\n",
      "INFO: Epoch 83.0\n",
      "Epoch 83.0: 44img [00:17,  2.59img/s, loss=0.366]\n",
      "Validation: 10img [00:02,  4.41img/s, loss=tensor(4.0176, device='cuda:0')]\n",
      "INFO: Train loss 0.3824725252660837\n",
      "INFO: Test loss  0.4463160037994385\n",
      "INFO: Epoch 84.0\n",
      "Epoch 84.0: 44img [00:16,  2.59img/s, loss=0.368]\n",
      "Validation: 10img [00:02,  4.67img/s, loss=tensor(4.3812, device='cuda:0')]\n",
      "INFO: Train loss 0.38086025620048697\n",
      "INFO: Test loss  0.4952114224433899\n",
      "INFO: Epoch 85.0\n",
      "Epoch 85.0: 44img [00:17,  2.58img/s, loss=0.374]\n",
      "Validation: 10img [00:01,  5.19img/s, loss=tensor(4.1171, device='cuda:0')]\n",
      "INFO: Train loss 0.3951418887485157\n",
      "INFO: Test loss  0.4571863114833832\n",
      "INFO: Epoch 86.0\n",
      "Epoch 86.0: 44img [00:16,  2.59img/s, loss=0.371]\n",
      "Validation: 10img [00:02,  4.97img/s, loss=tensor(4.1571, device='cuda:0')]\n",
      "INFO: Train loss 0.38561567190018564\n",
      "INFO: Test loss  0.46245136857032776\n",
      "INFO: Epoch 87.0\n",
      "Epoch 87.0: 44img [00:16,  2.60img/s, loss=0.37]\n",
      "Validation: 10img [00:01,  5.17img/s, loss=tensor(4.2590, device='cuda:0')]\n",
      "INFO: Train loss 0.3858560919761658\n",
      "INFO: Test loss  0.46850013732910156\n",
      "INFO: Epoch 88.0\n",
      "Epoch 88.0: 44img [00:16,  2.59img/s, loss=0.37]\n",
      "Validation: 10img [00:02,  4.98img/s, loss=tensor(4.0486, device='cuda:0')]\n",
      "INFO: Train loss 0.38455292650244444\n",
      "INFO: Test loss  0.451095312833786\n",
      "INFO: Epoch 89.0\n",
      "Epoch 89.0: 44img [00:16,  2.60img/s, loss=0.367]\n",
      "Validation: 10img [00:01,  5.00img/s, loss=tensor(4.3052, device='cuda:0')]\n",
      "INFO: Train loss 0.380645412613045\n",
      "INFO: Test loss  0.4852316081523895\n",
      "INFO: Epoch 90.0\n",
      "Epoch 90.0: 44img [00:16,  2.60img/s, loss=0.387]\n",
      "Validation: 10img [00:02,  4.95img/s, loss=tensor(4.6038, device='cuda:0')]\n",
      "INFO: Train loss 0.39359153129837743\n",
      "INFO: Test loss  0.5087312459945679\n",
      "INFO: Epoch 91.0\n",
      "Epoch 91.0: 44img [00:16,  2.59img/s, loss=0.377]\n",
      "Validation: 10img [00:01,  5.17img/s, loss=tensor(4.0458, device='cuda:0')]\n",
      "INFO: Train loss 0.3833580267700283\n",
      "INFO: Test loss  0.44991812109947205\n",
      "INFO: Epoch 92.0\n",
      "Epoch 92.0: 44img [00:16,  2.59img/s, loss=0.374]\n",
      "Validation: 10img [00:01,  5.02img/s, loss=tensor(4.0185, device='cuda:0')]\n",
      "INFO: Train loss 0.3820061697201294\n",
      "INFO: Test loss  0.45234259963035583\n",
      "INFO: Epoch 93.0\n",
      "Epoch 93.0: 44img [00:16,  2.60img/s, loss=0.368]\n",
      "Validation: 10img [00:01,  5.20img/s, loss=tensor(4.4674, device='cuda:0')]\n",
      "INFO: Train loss 0.38263250345533534\n",
      "INFO: Test loss  0.48772183060646057\n",
      "INFO: Epoch 94.0\n",
      "Epoch 94.0: 44img [00:16,  2.60img/s, loss=0.365]\n",
      "Validation: 10img [00:01,  5.07img/s, loss=tensor(4.2777, device='cuda:0')]\n",
      "INFO: Train loss 0.3778993690555746\n",
      "INFO: Test loss  0.4791816771030426\n",
      "INFO: Epoch 95.0\n",
      "Epoch 95.0: 44img [00:17,  2.59img/s, loss=0.358]\n",
      "Validation: 10img [00:01,  5.15img/s, loss=tensor(3.9607, device='cuda:0')]\n",
      "INFO: Train loss 0.3820020942525429\n",
      "INFO: Test loss  0.44356656074523926\n",
      "INFO: Epoch 96.0\n",
      "Epoch 96.0: 44img [00:16,  2.60img/s, loss=0.359]\n",
      "Validation: 10img [00:01,  5.02img/s, loss=tensor(3.9132, device='cuda:0')]\n",
      "INFO: Train loss 0.37498244914141565\n",
      "INFO: Test loss  0.4386880099773407\n",
      "INFO: Epoch 97.0\n",
      "Epoch 97.0: 44img [00:16,  2.59img/s, loss=0.364]\n",
      "Validation: 10img [00:01,  5.08img/s, loss=tensor(4.2251, device='cuda:0')]\n",
      "INFO: Train loss 0.3744169575246897\n",
      "INFO: Test loss  0.4628312587738037\n",
      "INFO: Epoch 98.0\n",
      "Epoch 98.0: 44img [00:16,  2.59img/s, loss=0.356]\n",
      "Validation: 10img [00:01,  5.06img/s, loss=tensor(3.8646, device='cuda:0')]\n",
      "INFO: Train loss 0.3698565458709543\n",
      "INFO: Test loss  0.4345684051513672\n",
      "INFO: Epoch 99.0\n",
      "Epoch 99.0: 44img [00:16,  2.60img/s, loss=0.356]\n",
      "Validation: 10img [00:01,  5.08img/s, loss=tensor(3.9901, device='cuda:0')]\n",
      "INFO: Train loss 0.37197262184186414\n",
      "INFO: Test loss  0.44132232666015625\n",
      "INFO: Best threshold  0.8\n",
      "/content/drive/MyDrive/Lamboise-Master/train.py:192: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  x = [int(i) for i in range(0, len(losses_train)-1)]\n",
      "<Figure size 640x480 with 1 Axes>\n",
      "<Figure size 640x480 with 1 Axes>\n",
      "\n",
      "Done in 3657 sec\n"
     ]
    }
   ],
   "source": [
    "!python /content/drive/MyDrive/Lamboise-Master/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4_V5JC18i6L"
   },
   "source": [
    "**Run predict.py to do the architecture change detection (UNet++)** <br>\n",
    "*!python path0 -i path1 -o path2* <br>\n",
    "(whole path is needed on colab\n",
    "\n",
    "*   path0 refers to the path of predict.py \n",
    "*   path1 refers to the path of the input file \n",
    "*   path2 refers to the path of the output file\n",
    "*   files needed to be arranged as follow(under the file):\n",
    "   *  instance_1\n",
    "      *  before.png\n",
    "      *  after.png\n",
    "      *  predicted.png (result 1\n",
    "   *  instance_2\n",
    "      *  before.png\n",
    "      *  after.png\n",
    "      *  predicted.png (result 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dHI0aQVj-IU"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/capstone/Lamboise-Master/predict.py -i /content/drive/MyDrive/capstone/Unet++/change_detection -o /content/drive/MyDrive/capstone/Unet++/change_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pdiYQi-Jfs3"
   },
   "source": [
    "Stitch label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E2BoroUJk07"
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    " \n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/Unet++/report/2018/' \n",
    "IMAGES_FORMAT = ['.png', '.PNG'] \n",
    "w=650            \n",
    "h=650           \n",
    "IMAGE_ROW = 5  \n",
    "IMAGE_COLUMN = 7  \n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/Unet++/report/2018/compose_image_2018.png'  \n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "image_names.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "if len(image_names) != IMAGE_ROW * IMAGE_COLUMN:\n",
    "    raise ValueError(\"Doesn't match！\")\n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN *w, IMAGE_ROW *h)) \n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (w, h),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * w, (y - 1) * h))\n",
    "    return to_image.save(IMAGE_SAVE_PATH) \n",
    "image_compose() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7eZ_KYOJmwX"
   },
   "source": [
    "Stitch 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVFOPCFOJpmg"
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    " \n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/Unet++/report/2021/' \n",
    "IMAGES_FORMAT = ['.png', '.PNG'] \n",
    "w=650            \n",
    "h=650           \n",
    "IMAGE_ROW = 5  \n",
    "IMAGE_COLUMN = 7  \n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/Unet++/report/2021/compose_image_2021.png'  \n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "image_names.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "if len(image_names) != IMAGE_ROW * IMAGE_COLUMN:\n",
    "    raise ValueError(\"Doesn't match！\")\n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN *w, IMAGE_ROW *h)) \n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (w, h),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * w, (y - 1) * h))\n",
    "    return to_image.save(IMAGE_SAVE_PATH) \n",
    "image_compose() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkGCRLNNJs3r"
   },
   "source": [
    "Stitch mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x01ecu4nJuxY"
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import os\n",
    " \n",
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/Unet++/report/mask/' \n",
    "IMAGES_FORMAT = ['.png', '.PNG'] \n",
    "w=650            \n",
    "h=650           \n",
    "IMAGE_ROW = 5  \n",
    "IMAGE_COLUMN = 7  \n",
    "IMAGE_SAVE_PATH = '/content/drive/MyDrive/capstone/Unet++/report/mask/compose_image_mask.png'  \n",
    "image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "image_names.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "if len(image_names) != IMAGE_ROW * IMAGE_COLUMN:\n",
    "    raise ValueError(\"Doesn't match！\")\n",
    "def image_compose():\n",
    "    to_image = Image.new('RGB', (IMAGE_COLUMN *w, IMAGE_ROW *h)) \n",
    "    for y in range(1, IMAGE_ROW + 1):\n",
    "        for x in range(1, IMAGE_COLUMN + 1):\n",
    "            from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize(\n",
    "                (w, h),Image.ANTIALIAS)\n",
    "            to_image.paste(from_image, ((x - 1) * w, (y - 1) * h))\n",
    "    return to_image.save(IMAGE_SAVE_PATH) \n",
    "image_compose() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzYDDxwsJ33q"
   },
   "source": [
    "Code for predicted image processing that make the result more distingishable, including **enhance contrast & brightness**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxsbpkRzJwqi"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfvqbw-nKCF8"
   },
   "source": [
    "If first processing the cropped images then stitching the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yn6XSDZKCza"
   },
   "outputs": [],
   "source": [
    "IMAGES_PATH = '/content/drive/MyDrive/capstone/Lamboise-Master/TEST' # input path（predict\n",
    "IMAGES_FORMAT = ['.png', '.PNG']  \n",
    "\n",
    "# two steps\n",
    "IMAGE_SAVE_PATH_1 = '/content/drive/MyDrive/capstone/Lamboise-Master/TEST'  # saving path 1(for enhancing contrast)\n",
    "IMAGE_SAVE_PATH_2 = '/content/drive/MyDrive/capstone/Lamboise-Master/TEST'  # saving path 2(for enhancing brightness)\n",
    "\n",
    "image_names_1 = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "for image_1 in image_names_1: # increase contrast\n",
    "  im = Image.open(IMAGES_PATH+'/'+image_1) # read the image\n",
    "  enhancer = ImageEnhance.Contrast(im) # image contrast enhancer\n",
    "  factor = 3 #increase contrast\n",
    "  im_output = enhancer.enhance(factor)\n",
    "  im_output.save(IMAGE_SAVE_PATH_1+'/'+image_1)\n",
    "\n",
    "image_names_2 = [name for name in os.listdir(IMAGES_SAVE_PATH_1) for item in IMAGES_FORMAT if\n",
    "               os.path.splitext(name)[1] == item]\n",
    "\n",
    "for image_2 in image_names_2: # increase brightness\n",
    "  im = Image.open(IMAGE_SAVE_PATH_1+'/'+image_2) # read the image\n",
    "  enhancer = ImageEnhance.Brightness(im) # image brightness enhancer\n",
    "  factor = 3 #increase brightness\n",
    "  im_output = enhancer.enhance(factor)\n",
    "  im_output.save(IMAGE_SAVE_PATH_2+'/'+image_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEre5BcgKJ5o"
   },
   "source": [
    "If first stitching then process the images **(recommended)**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIxDk3dxKNEQ"
   },
   "outputs": [],
   "source": [
    "#read the image\n",
    "im = Image.open(\"/content/drive/MyDrive/capstone/Unet++/report/mask/compose_image_mask.png\") # input path\n",
    "\n",
    "#image contrast enhancer\n",
    "enhancer = ImageEnhance.Contrast(im)\n",
    "\n",
    "factor = 3 #increase contrast\n",
    "im_output = enhancer.enhance(factor)\n",
    "im_output.save('/content/drive/MyDrive/capstone/Unet++/report/mask/more-contrast-image.png')\n",
    "\n",
    "im1 = Image.open(\"/content/drive/MyDrive/capstone/Unet++/report/mask/more-contrast-image.png\")\n",
    "\n",
    "#image brightness enhancer\n",
    "enhancer = ImageEnhance.Brightness(im1)\n",
    "\n",
    "factor = 3 #brightens the image\n",
    "im_output = enhancer.enhance(factor)\n",
    "im_output.save('/content/drive/MyDrive/capstone/Unet++/report/mask/brightened-image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uDmhK4gKU-N"
   },
   "source": [
    "Do a **multiply** on the mask and labelled image to keep the changed zones while shows the development of the two types of architectures. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82tnxdEbKVpv"
   },
   "outputs": [],
   "source": [
    "# Importing Image and ImageChops module from PIL package\n",
    "from PIL import Image, ImageChops\n",
    "\t\n",
    "# create label\n",
    "label = Image.open(r\"/content/drive/MyDrive/capstone/Unet++/report/label/compose_image_label.png\")\n",
    "\n",
    "# ValueError: images do not match, need to match image mode\n",
    "label = label.convert(\"RGB\")\n",
    "\n",
    "# creat mask\n",
    "mask = Image.open(r\"//content/drive/MyDrive/capstone/Unet++/report/mask/brightened-image.png\")\n",
    "mask = mask.convert(\"RGB\")\t\n",
    "\n",
    "# applying multiply method\n",
    "im3 = ImageChops.multiply(label,mask)\n",
    "im3.save('/content/drive/MyDrive/capstone/Unet++/report/result.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxytFbyJewWqp/XTxiAj8A",
   "collapsed_sections": [
    "LajkitF1iyuT"
   ],
   "mount_file_id": "18Geosi_uRAj9h9CQ2YsoHA8MvDfoabTy",
   "name": "Final change detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
